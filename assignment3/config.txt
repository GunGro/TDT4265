(conv relu conv relu pool) * 3

        num_filters = 64  # Set number of filters in first conv layer


        self.conv_layers = nn.Sequential(
           nn.Conv2d(image_channels, num_filters, kernel_size=5,stride=1,padding=2)
          ,nn.ReLU()
          ,nn.Conv2d(num_filters, num_filters, kernel_size=5,stride=1,padding=2)
          ,nn.ReLU()
          ,nn.MaxPool2d(2, 2)
          ,nn.Conv2d(num_filters, num_filters*2, kernel_size=5,stride=1,padding=2)
          ,nn.ReLU()
          ,nn.Conv2d(num_filters*2, num_filters*2, kernel_size=5,stride=1,padding=2)
          ,nn.ReLU()
          ,nn.MaxPool2d(2, 2)
          ,nn.Conv2d(num_filters*2, num_filters*4, kernel_size=5,stride=1,padding=2)
          ,nn.ReLU()
          ,nn.Conv2d(num_filters*4, num_filters*4, kernel_size=5,stride=1,padding=2)
          ,nn.ReLU()
          ,nn.MaxPool2d(2, 2)
        )
        self.linear_layers = nn.Sequential(
             nn.Flatten()
            ,nn.Linear(num_filters*4*4*4, 60)
            ,nn.ReLU()
            ,nn.Linear(60, 10)
        )


Training accuracy and loss was: 0.9323213015647226  and  tensor(0.1959, device='cuda:0')
Validation accuracy and loss was: 0.7622  and  tensor(0.8443, device='cuda:0')
Test accuracy and loss was: 0.7585  and  tensor(0.8545, device='cuda:0')

with batchnorms and L2-reg of 0.005: 

       num_filters = 32  # Set number of filters in first conv layer

       self.conv_layers = nn.Sequential(
           nn.Conv2d(image_channels, num_filters, kernel_size=5,stride=1,padding=2)
          ,nn.ReLU()
          ,nn.BatchNorm2d(num_filters)
          ,nn.Conv2d(num_filters, num_filters, kernel_size=5,stride=1,padding=2)
          ,nn.ReLU()
          ,nn.BatchNorm2d(num_filters)
          ,nn.MaxPool2d(2, 2)
          
          
          ,nn.Conv2d(num_filters, num_filters*2, kernel_size=5,stride=1,padding=2)
          ,nn.ReLU()
          ,nn.BatchNorm2d(num_filters*2)
          ,nn.Conv2d(num_filters*2, num_filters*2, kernel_size=5,stride=1,padding=2)
          ,nn.ReLU()
          ,nn.BatchNorm2d(num_filters*2)
          ,nn.MaxPool2d(2, 2)
          
          
          ,nn.Conv2d(num_filters*2, num_filters*4, kernel_size=5,stride=1,padding=2)
          ,nn.ReLU()
          ,nn.BatchNorm2d(num_filters*4)
          ,nn.Conv2d(num_filters*4, num_filters*4, kernel_size=5,stride=1,padding=2)
          ,nn.ReLU()
          ,nn.BatchNorm2d(num_filters*4)
          ,nn.MaxPool2d(2, 2)
          
          
          
        )
        self.linear_layers = nn.Sequential(
             nn.Flatten()
            ,nn.Linear(num_filters*4*4*4, 60)
            ,nn.ReLU()
            ,nn.Linear(60, 10)
        )

Training accuracy and loss was: 0.9299431009957326  and  tensor(0.2118, device='cuda:0')
Validation accuracy and loss was: 0.8066  and  tensor(0.5737, device='cuda:0')
Test accuracy and loss was: 0.8102  and  tensor(0.5843, device='cuda:0')

without regularizing 

 Training accuracy and loss was: 0.9277427098150782  and  tensor(0.2095, device='cuda:0')
Validation accuracy and loss was: 0.793  and  tensor(0.6889, device='cuda:0')
Test accuracy and loss was: 0.7937  and  tensor(0.6907, device='cuda:0')